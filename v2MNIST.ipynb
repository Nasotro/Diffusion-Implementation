{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from models.unet import Unet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.utils import show_image\n",
    "from utils.noise import CosineNoiseAdder\n",
    "\n",
    "from data.dataset import MNIST_Dataset, CIFAR10_Dataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start with shape torch.Size([1, 1, 32, 32])\n",
      "label shape : torch.Size([1])\n",
      "label_embeddings shape : torch.Size([1, 32])\n",
      "label_embeddings shape : torch.Size([1, 32, 1, 1])\n",
      "label_embeddings shape : torch.Size([1, 32, 32, 32])\n",
      "after concatenating the timestep embedds : torch.Size([1, 65, 32, 32])\n",
      "down block 0, with shape torch.Size([1, 65, 32, 32])\n",
      "down block 1, with shape torch.Size([1, 64, 16, 16])\n",
      "down block 2, with shape torch.Size([1, 128, 8, 8])\n",
      "after bottleneck : shape = torch.Size([1, 256, 8, 8])\n",
      "up block 0, with shape torch.Size([1, 256, 8, 8]), and skip shape : torch.Size([1, 256, 8, 8])\n",
      "up block 1, with shape torch.Size([1, 128, 16, 16]), and skip shape : torch.Size([1, 128, 16, 16])\n",
      "after final : shape = torch.Size([1, 1, 32, 32])\n",
      "torch.Size([1, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# testing net shapes\n",
    "net = Unet(64, depth=3, time_embed_dim=32, label_emb_dim=32,\n",
    "           num_label=10, initial_channels=1, conv_layers=2)\n",
    "test_img = torch.randn(1, 1, 32, 32)\n",
    "test_time = torch.tensor([1])\n",
    "test_label = torch.tensor([1])\n",
    "print(net(test_img, test_time, test_label, verbose=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # dataset\n",
    "    batch_size = 4\n",
    "    \n",
    "    # noise\n",
    "    B_0 = 1e-4\n",
    "    B_T = 2e-2\n",
    "    T = 500\n",
    "    schedule_type = 'cosine'\n",
    "    s = 0.008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseDataset():\n",
    "    def __init__(self, imgs_dataset, noise_schedule = None):\n",
    "        self.imgs_dataset = imgs_dataset\n",
    "        self.noise_schedule = noise_schedule if noise_schedule else CosineNoiseAdder()       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.imgs_dataset[idx]\n",
    "        t = torch.randint(self.noise_schedule.T, (1, )).squeeze()\n",
    "        noisy_img, noise = self.noise_schedule.image_at_time_step(img, t)\n",
    "        return noisy_img, noise, t, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight, gain=1)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model:nn.Module, _test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, (noisy_imgs, noises, time_steps, labels) in enumerate(_test_loader):\n",
    "            noisy_imgs, noises, time_steps, labels = noisy_imgs.to(device), noises.to(device), time_steps.to(device), labels.to(device)\n",
    "            outputs = model(noisy_imgs, time_steps, labels)\n",
    "            loss = criterion(outputs, noises)\n",
    "            losses.append(loss.item())\n",
    "            # print(loss, losses)\n",
    "            # print(f\"Batch {i}, Loss: {loss.item()}\")\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "n_epochs = 10\n",
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "dropout = 0.2\n",
    "max_time_steps = 200\n",
    "patience = 5000\n",
    "\n",
    "\n",
    "test = None\n",
    "train = None\n",
    "net = None\n",
    "\n",
    "CosineNoise = CosineNoiseAdder(max_time_steps)\n",
    "\n",
    "\n",
    "# dataset = \"CIFAR10\"\n",
    "dataset = \"MNIST\"\n",
    "\n",
    "if dataset == \"MNIST\":\n",
    "    initial_channels = 1\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.Normalize((0.5,), (0.5, ))])\n",
    "    \n",
    "    train = NoiseDataset(MNIST_Dataset(transform=trans), CosineNoise)\n",
    "    test = NoiseDataset(MNIST_Dataset('test', transform=trans), CosineNoise)\n",
    "    \n",
    "    net = Unet(32, depth=2, time_embed_dim=16, label_emb_dim=16,\n",
    "           num_label=10, initial_channels=initial_channels, \n",
    "           conv_layers=3, dropout=dropout)\n",
    "\n",
    "if dataset == \"CIFAR10\":\n",
    "    initial_channels = 3\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "    train = NoiseDataset(CIFAR10_Dataset(transform=trans), CosineNoise)\n",
    "    test = NoiseDataset(CIFAR10_Dataset(transform=trans, split='test'), CosineNoise)\n",
    "    \n",
    "    net = Unet(64, depth=3, time_embed_dim=16, label_emb_dim=16,\n",
    "           num_label=10, initial_channels=initial_channels, \n",
    "           conv_layers=2, dropout=dropout)\n",
    "\n",
    "show_image(train[1][0], title=\"Noisy Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = torch.utils.data.Subset(train, range(0, 1000))\n",
    "# test = torch.utils.data.Subset(test, range(0, 100))\n",
    "train_loader = DataLoader(train, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "net.apply(init_weights)\n",
    "\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.316)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=n_epochs * len(train_loader), eta_min=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=50, min_lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 3750/3750 [02:55<00:00, 21.40it/s, Loss=0.0283, Val Loss=0.0391, lr=0.00098] \n",
      "Epoch 2/10: 100%|██████████| 3750/3750 [02:52<00:00, 21.73it/s, Loss=0.0331, Val Loss=0.0348, lr=0.000914]\n",
      "Epoch 3/10: 100%|██████████| 3750/3750 [02:41<00:00, 23.19it/s, Loss=0.0229, Val Loss=0.0317, lr=0.000808]\n",
      "Epoch 4/10: 100%|██████████| 3750/3750 [02:38<00:00, 23.72it/s, Loss=0.0359, Val Loss=0.0298, lr=0.000673]\n",
      "Epoch 5/10: 100%|██████████| 3750/3750 [02:33<00:00, 24.45it/s, Loss=0.0315, Val Loss=0.0291, lr=0.000521]\n",
      "Epoch 6/10:  30%|███       | 1125/3750 [00:50<01:58, 22.16it/s, Loss=0.024, Val Loss=0.0287, lr=0.000474]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, lr: {scheduler.get_last_lr()[0]}')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(model, _test_loader, criterion, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (noisy_imgs, noises, time_steps, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(_test_loader):\n\u001b[1;32m----> 6\u001b[0m         noisy_imgs, noises, time_steps, labels \u001b[38;5;241m=\u001b[39m noisy_imgs\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mnoises\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, time_steps\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(noisy_imgs, time_steps, labels)\n\u001b[0;32m      8\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, noises)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "net.to(device)\n",
    "\n",
    "# keep track of the loss\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_loss = np.inf\n",
    "best_loss_i = 0\n",
    "stoping = False\n",
    "eval_every = len(train_loader) // 10\n",
    "\n",
    "net.train()\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{n_epochs}', leave=True)\n",
    "    for i, batch in enumerate(train_loader_tqdm):\n",
    "        noisy_imgs, noises, time_steps, labels = batch\n",
    "        noisy_imgs, noises, time_steps, labels = noisy_imgs.to(\n",
    "            device), noises.to(device), time_steps.to(device), labels.to(device)\n",
    "        # print(noisy_imgs.shape, noises.shape, time_steps.shape, labels.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predicted_noise = net(noisy_imgs, time_steps, labels, verbose=False)\n",
    "        loss = criterion(predicted_noise, noises)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        if i % eval_every == 0 and i > 0:\n",
    "            \n",
    "            val_loss = eval_model(net, test_loader, criterion, device)\n",
    "            val_losses.append(val_loss)\n",
    "            # print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, lr: {scheduler.get_last_lr()[0]}')\n",
    "            train_loader_tqdm.set_postfix({'Loss': loss.item(), 'Val Loss': val_loss, 'lr': scheduler.get_last_lr()[0]})\n",
    "\n",
    "            \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_loss_i = epoch * len(train_loader) + i\n",
    "                torch.save(net.state_dict(), 'best_model_MNIST.pth')\n",
    "\n",
    "            if epoch * len(train_loader) + i - best_loss_i > patience:\n",
    "                print(\"Stopping early\")\n",
    "                stoping = True\n",
    "                break\n",
    "\n",
    "        # show_image(noisy_imgs[0], title=\"noisy image\")\n",
    "        # show_image(predicted_noise[0], title=\"predicted noise\")\n",
    "\n",
    "        # break\n",
    "        scheduler.step()\n",
    "        # train_loader_tqdm.set_postfix({'Loss': loss.item(), 'Val Loss': val_loss, 'lr': scheduler.get_last_lr()[0]})\n",
    "    # if epoch % 4 == 0:\n",
    "    #     scheduler.step()\n",
    "    if stoping:\n",
    "        break\n",
    "    # break\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "train_losses_resized = [np.mean(train_losses[i * eval_every:(i + 1) * eval_every]) for i in range(len(val_losses))]\n",
    "plt.plot(np.arange(0, len(train_losses_resized)) * eval_every / len(train_loader), train_losses_resized, label='Training Loss (averaged)')\n",
    "plt.plot(np.arange(0, len(val_losses)) * eval_every / len(train_loader), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (time_emb): SinusoidalPositionEmbeddings()\n",
       "  (label_emb): Embedding(10, 16)\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock(\n",
       "      (silu): SiLU()\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (norms): ModuleList(\n",
       "        (0-2): 3 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dropouts): ModuleList(\n",
       "        (0-2): 3 x Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (max_pooling): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList()\n",
       "  (bottleneck): BottleNeck(\n",
       "    (convs): ModuleList(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1-2): 2 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-2): 3 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropouts): ModuleList(\n",
       "      (0-2): 3 x Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (up_conv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (silu): SiLU()\n",
       "  )\n",
       "  (final): FinalBlock(\n",
       "    (silu): SiLU()\n",
       "    (convs): ModuleList(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1-2): 2 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-2): 3 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropouts): ModuleList(\n",
       "      (0-2): 3 x Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (final_conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('best_model_MNIST.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m max_time_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      3\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 4\u001b[0m xt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn((n_samples, initial_channels, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m T \u001b[38;5;241m=\u001b[39m max_time_steps\n\u001b[0;32m      6\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.008\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "max_time_steps = 200\n",
    "\n",
    "n_samples = 1\n",
    "xt = torch.randn((n_samples, initial_channels, 32, 32)).to(device)\n",
    "T = max_time_steps\n",
    "s = 0.008\n",
    "\n",
    "# 'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "label = torch.tensor([5], device=device)\n",
    "\n",
    "CosineNoise = CosineNoiseAdder(max_time_steps, s)\n",
    "\n",
    "# print(CosineNoise.get_alpha_t(T))\n",
    "for _ in range(1):\n",
    "    with torch.no_grad():\n",
    "        full_img = torch.tensor([], device=device)\n",
    "        full_predicted_noise = torch.tensor([], device=device)\n",
    "    \n",
    "        xt = torch.randn((n_samples, initial_channels, 32, 32)).to(device)\n",
    "        for t in torch.arange(max_time_steps-1, -1, -1):\n",
    "            t = t.expand((n_samples)).to(device)\n",
    "            a_t = CosineNoise.get_alpha_t(t)\n",
    "            alpha_t_barre = CosineNoise.get_alpha_t_barre(t)\n",
    "            sigma = torch.sqrt(1-a_t).view(n_samples, 1, 1, 1)\n",
    "            z = torch.randn_like(xt)\n",
    "            # print(xt.shape)\n",
    "            epsilon = net(xt, t, label)\n",
    "            a = ((1 - a_t)/(torch.sqrt(1 - alpha_t_barre))).view(n_samples, 1, 1, 1)\n",
    "            b = (1/torch.sqrt(a_t)).view(n_samples, 1, 1, 1)\n",
    "            \n",
    "            if t.item() % (max_time_steps / 10) == 0 or t.item() == max_time_steps-1:\n",
    "                # print(t.item())\n",
    "                full_img = torch.cat((full_img, xt), 3)\n",
    "                full_predicted_noise = torch.cat((full_predicted_noise, epsilon), 3)\n",
    "                # print(xt.shape)\n",
    "                # show_image(xt[0], f'{t.item()}%')\n",
    "                # show_image(full_img[0])\n",
    "            \n",
    "            # print(t[0].item(), a_t[0].item(), alpha_t_barre[0].item(), sigma[0].item(), a[0].item(), b[0].item(), z.shape, epsilon.shape, sep=' | ')\n",
    "            # print(xt.shape, epsilon.shape)\n",
    "            \n",
    "            xt = b*(xt - a*epsilon) + sigma*z\n",
    "\n",
    "            # xt = torch.sqrt(1 - a_t).view(n_samples, 1, 1, 1) * epsilon + sigma * z\n",
    "            \n",
    "            # xt = b * (xt - torch.sqrt(1-alpha_t_barre)*epsilon) + sigma*z\n",
    "            \n",
    "            # print(xt[0][0][0][0], xt[0][1][0][0], xt[0][2][0][0])\n",
    "            # print(xt[0])\n",
    "\n",
    "        show_image(xt[0])\n",
    "        \n",
    "    # print(full_img.shape)\n",
    "        show_image(full_img[0])\n",
    "        # show_image(full_predicted_noise[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
